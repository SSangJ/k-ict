{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:39:42.223913400Z",
     "start_time": "2023-10-04T11:39:38.881222700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:39:51.412782300Z",
     "start_time": "2023-10-04T11:39:50.082803500Z"
    }
   },
   "id": "db12b97a04b1d87c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def display_images():\n",
    "    fig, subplots = plt.subplots(1,5, figsize=(13,6))\n",
    "    for i in range(5):\n",
    "        axil = subplots.flat[i]\n",
    "        original_img = Image.fromarray(cifar10.data[i])\n",
    "        axil.imshow(original_img)\n",
    "        axil.set_title('original_img')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:42:42.036581700Z",
     "start_time": "2023-10-04T11:42:42.002669Z"
    }
   },
   "id": "fd1b88330cd6a5c7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:42:42.177032Z",
     "start_time": "2023-10-04T11:42:42.151101700Z"
    }
   },
   "id": "1dafd83c95386566"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 데이터셋의 루트 디렉터리와 이미지 폴더를 지정합니다.\n",
    "root_dir = '../data/'  # 데이터셋의 루트 디렉터리 경로\n",
    "train_folder = 'kfood_train/train'  # 이미지가 있는 폴더의 이름\n",
    "val_folder = 'kfood_val/val'  # 이미지가 있는 폴더의 이름"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T12:00:33.540351200Z",
     "start_time": "2023-10-04T12:00:33.503331900Z"
    }
   },
   "id": "4345067e3723576d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 이미지 전처리를 위한 변환(transform)을 정의합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),  # 이미지 크기를 조절합니다.\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환합니다.\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 이미지를 정규화합니다.\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T12:02:05.206519400Z",
     "start_time": "2023-10-04T12:02:05.188731800Z"
    }
   },
   "id": "93ab4cca8d1508d1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 데이터셋을 불러옵니다.\n",
    "trainset = torchvision.datasets.ImageFolder(\n",
    "    root=root_dir + train_folder,\n",
    "    transform=transform\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T12:02:35.052740500Z",
     "start_time": "2023-10-04T12:02:34.857413700Z"
    }
   },
   "id": "ee8bee522679d7bc"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 데이터셋을 불러옵니다.\n",
    "valset = torchvision.datasets.ImageFolder(\n",
    "    root=root_dir + val_folder,\n",
    "    transform=transform\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T12:02:35.178384900Z",
     "start_time": "2023-10-04T12:02:35.109354100Z"
    }
   },
   "id": "25fc01d3c03f53df"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# 데이터 로더를 설정합니다.\n",
    "batch_size = 8 # 배치 크기를 지정합니다.\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  # 데이터를 섞어서 로드합니다.\n",
    "    num_workers=4  # 데이터를 병렬로 로드할 워커 수를 지정합니다.\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:15.878145300Z",
     "start_time": "2023-10-04T13:55:15.851637400Z"
    }
   },
   "id": "ab3f950aa0ec89cb"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# 데이터 로더를 설정합니다.\n",
    "batch_size = 8  # 배치 크기를 지정합니다.\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  # 데이터를 섞어서 로드합니다.\n",
    "    num_workers=4  # 데이터를 병렬로 로드할 워커 수를 지정합니다.\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:16.150214400Z",
     "start_time": "2023-10-04T13:55:16.122065Z"
    }
   },
   "id": "c594eadb80d5d7b1"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['갈비구이', '갈치구이', '감자전', '경단', '계란국', '계란말이', '계란후라이', '고등어구이', '곱창구이', '김밥', '김치볶음밥', '김치전', '꿀떡', '누룽지', '닭갈비', '더덕구이', '동그랑땡', '떡갈비', '떡국_만두국', '무국', '미역국', '북엇국', '불고기', '비빔밥', '삼겹살', '새우볶음밥', '생선전', '송편', '시래기국', '알밥', '유부초밥', '육개장', '잡곡밥', '장어구이', '조개구이', '조기구이', '주먹밥', '콩나물국', '파전', '호박전', '황태구이', '훈제오리']\n"
     ]
    }
   ],
   "source": [
    "# 클래스 레이블을 확인합니다.\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:16.590501700Z",
     "start_time": "2023-10-04T13:55:16.554598700Z"
    }
   },
   "id": "94719d7e1b0cbc80"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['갈비구이', '갈치구이', '감자전', '경단', '계란국', '계란말이', '계란후라이', '고등어구이', '곱창구이', '김밥', '김치볶음밥', '김치전', '꿀떡', '누룽지', '닭갈비', '더덕구이', '동그랑땡', '떡갈비', '떡국_만두국', '무국', '미역국', '북엇국', '불고기', '비빔밥', '삼겹살', '새우볶음밥', '생선전', '송편', '시래기국', '알밥', '유부초밥', '육개장', '잡곡밥', '장어구이', '조개구이', '조기구이', '주먹밥', '콩나물국', '파전', '호박전', '황태구이', '훈제오리']\n"
     ]
    }
   ],
   "source": [
    "# 클래스 레이블을 확인합니다.\n",
    "classes = valset.classes\n",
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:17.091944400Z",
     "start_time": "2023-10-04T13:55:17.061025400Z"
    }
   },
   "id": "c30cc9398aa72bc"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:17.940328700Z",
     "start_time": "2023-10-04T13:55:17.920382100Z"
    }
   },
   "id": "97ead0eb2f8cfc9"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "resnet_pt = models.resnet18(pretrained=False)\n",
    "# freezing\n",
    "# for param in resnet_pt.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# fc layer 수정\n",
    "fc_in_features = resnet_pt.fc.in_features\n",
    "resnet_pt.fc = nn.Linear(fc_in_features, len(classes))\n",
    "resnet_pt = resnet_pt.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:18.377220400Z",
     "start_time": "2023-10-04T13:55:18.230612500Z"
    }
   },
   "id": "d42af719a01d7078"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 42]          21,546\n",
      "================================================================\n",
      "Total params: 11,198,058\n",
      "Trainable params: 11,198,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 42.72\n",
      "Estimated Total Size (MB): 119.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet_pt, (3,244,244))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:18.986752600Z",
     "start_time": "2023-10-04T13:55:18.950849600Z"
    }
   },
   "id": "683e5ffd4f0a9401"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet_pt.parameters() , lr = 0.001 , momentum = 0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:19.890040100Z",
     "start_time": "2023-10-04T13:55:19.858995400Z"
    }
   },
   "id": "1aba4bc133be30b9"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=42, bias=True)\n)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_pt.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:55:20.694515Z",
     "start_time": "2023-10-04T13:55:20.674567300Z"
    }
   },
   "id": "415457dafb87e96c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.190, val_loss: 3.793\n",
      "[1,   200] loss: 0.184, val_loss: 3.531\n",
      "[1,   300] loss: 0.175, val_loss: 3.483\n",
      "[1,   400] loss: 0.175, val_loss: 3.514\n",
      "[1,   500] loss: 0.172, val_loss: 3.326\n",
      "[1,   600] loss: 0.171, val_loss: 3.328\n",
      "[1,   700] loss: 0.172, val_loss: 3.311\n",
      "[1,   800] loss: 0.167, val_loss: 3.373\n",
      "[1,   900] loss: 0.163, val_loss: 3.246\n",
      "[1,  1000] loss: 0.166, val_loss: 3.264\n",
      "[1,  1100] loss: 0.161, val_loss: 3.074\n",
      "[1,  1200] loss: 0.163, val_loss: 3.150\n",
      "[1,  1300] loss: 0.159, val_loss: 3.108\n",
      "[1,  1400] loss: 0.161, val_loss: 3.036\n",
      "[1,  1500] loss: 0.156, val_loss: 3.100\n",
      "[1,  1600] loss: 0.159, val_loss: 3.116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[68], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m resnet_pt\u001B[38;5;241m.\u001B[39meval()  \u001B[38;5;66;03m# 모델을 평가 모드로 설정\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():  \u001B[38;5;66;03m# 그라디언트 계산 비활성화\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m val_data \u001B[38;5;129;01min\u001B[39;00m valloader:\n\u001B[0;32m     27\u001B[0m         val_inputs, val_labels \u001B[38;5;241m=\u001B[39m val_data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device), val_data[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     28\u001B[0m         val_outputs \u001B[38;5;241m=\u001B[39m resnet_pt(val_inputs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1035\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1042\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    running_val_loss = 0.0  # validation loss를 저장하기 위한 변수 추가\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet_pt(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # validation loss 계산\n",
    "        if i % 100 == 99:\n",
    "            resnet_pt.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "            with torch.no_grad():  # 그라디언트 계산 비활성화\n",
    "                for val_data in valloader:\n",
    "                    val_inputs, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = resnet_pt(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_labels)\n",
    "                    running_val_loss += val_loss.item()\n",
    "\n",
    "            resnet_pt.train()  # 모델을 다시 훈련 모드로 설정\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}, val_loss: {running_val_loss / len(valloader):.3f}')\n",
    "            running_loss = 0.0\n",
    "            running_val_loss = 0.0\n",
    "\n",
    "print('finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:01:02.590942Z",
     "start_time": "2023-10-04T13:55:21.636238700Z"
    }
   },
   "id": "a8d6f260b32d12a1"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 8 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = resnet_pt(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _ , predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy {100 * correct // total} %') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:54:24.919673300Z",
     "start_time": "2023-10-04T13:54:08.292202Z"
    }
   },
   "id": "d561ca0a09b349b3"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 80 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = resnet_pt(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _ , predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T13:18:51.166993400Z",
     "start_time": "2023-10-04T13:17:49.690987600Z"
    }
   },
   "id": "46735929c90164a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ccdd3887925b08d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
